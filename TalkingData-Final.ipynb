{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and file reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n",
      "{'test.csv': '/home/users/nikhil/af/data/test.csv', 'test_supplement.csv.zip': '/home/users/nikhil/af/data/test_supplement.csv.zip', 'sample_submission.csv': '/home/users/nikhil/af/data/sample_submission.csv', 'train.csv': '/home/users/nikhil/af/data/mnt/ssd/kaggle-talkingdata2/competition_files/train.csv', 'test_supplement.csv': '/home/users/nikhil/af/data/data/test_supplement.csv'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from talking_utils import *\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "    \n",
    "from data_preprocess import *\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "%autosave 30\n",
    "\n",
    "mpl.rcParams['font.size']=12                #10 \n",
    "mpl.rcParams['savefig.dpi']=100             #72 \n",
    "mpl.rcParams['figure.subplot.bottom']=.1 \n",
    "\n",
    "datafiles = {}\n",
    "\n",
    "for folder, subs, files in os.walk('af/data'):\n",
    "  for filename in files:\n",
    "        datafiles[filename] = os.path.abspath(os.path.join(folder, filename))\n",
    "        \n",
    "print(datafiles)\n",
    "\n",
    "def save_df_pd(df,path):\n",
    "    print('Args passed',path)\n",
    "    df.to_csv(path,index=False)\n",
    "    \n",
    "def save_dictionary(dic,path):\n",
    "    print('Saving to ',path)\n",
    "    np.save(path, dic)\n",
    "    \n",
    "def save_keras_model(model,path):\n",
    "    model.save(path)\n",
    "    \n",
    "def save_in_thread(args,func):\n",
    "    save_thread = threading.Thread(target=func, args=args)\n",
    "    save_thread.start()\n",
    "    return save_thread\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "make_keras_picklable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Data was preprocessed earlier with features earlier, code is in talking_utils.py\n",
    "#Saved the \n",
    "\n",
    "with open('obj/train_np_20gp.pkl', 'rb') as handle:\n",
    "    train_np = pickle.load(handle)\n",
    "    \n",
    "with open('obj/test_np_20gp.pkl', 'rb') as handle:\n",
    "    test_np = pickle.load(handle)\n",
    "\n",
    "with open('obj/y_np_20gp.pkl', 'rb') as handle:\n",
    "    y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikit stratified test/train split for a unbiased test set\n",
    "train_data,val_data,train_labels,val_labels = get_evenly_split_train_val(0.1, y.ravel(), train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_keras_layer_model(train_np, test_np, 100, 32, 0.5,[64],[2],[4])\n",
    "\n",
    "lent = 180903890\n",
    "\n",
    "model = get_keras_model_compiled(lent, 2**18, 1, 0.001, 0.0001, model)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class weights due to difference in examples of both classes, ran a loop to come up with a better threshold values which reduces the classes incorrectly marked 0\n",
    "class_weight = {0:1-0.6860999999999795,1:.6860999999999795}\n",
    "del train_np\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "model.fit(train_data, train_labels, batch_size=int((2**18)), epochs=1,shuffle=True,class_weight=class_weight,verbose=1,validation_data=(val_data, val_labels))\n",
    "\n",
    "#saving wts when ran training, over night\n",
    "model_json = model.to_json()\n",
    "with open(\"model_WT6.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "model.save_weights(\"model_wt6.h5\")\n",
    "save_obj(model,'model_conv_wt6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_np,batch_size=2**19,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['click_id'] = np.arange(0,18790469,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_attributed'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('subm_conv_wtm.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
